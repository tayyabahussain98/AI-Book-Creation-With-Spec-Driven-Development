# Human-Robot Interaction Patterns Specification

**Purpose**: Illustrate common HRI scenarios that Unity's visual fidelity enables for training and testing

**Diagram Type**: conceptual

## HRI Scenario Categories

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HUMAN-ROBOT INTERACTION PATTERNS                          â”‚
â”‚                    (Unity Simulation Scenarios)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PHYSICAL INTERACTION  â”‚  â”‚    SOCIAL NAVIGATION    â”‚  â”‚   COMMUNICATION     â”‚
â”‚                         â”‚  â”‚                         â”‚  â”‚                     â”‚
â”‚  â€¢ Object Handoff       â”‚  â”‚  â€¢ Personal Space       â”‚  â”‚  â€¢ Gesture Recognitionâ”‚
â”‚  â€¢ Collaborative Lift   â”‚  â”‚  â€¢ Path Prediction      â”‚  â”‚  â€¢ Gaze Following    â”‚
â”‚  â€¢ Tool Exchange        â”‚  â”‚  â€¢ Group Navigation     â”‚  â”‚  â€¢ Speech Interactionâ”‚
â”‚  â€¢ Contact Detection    â”‚  â”‚  â€¢ Door/Elevator        â”‚  â”‚  â€¢ Emotion Response  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pattern 1: Object Handoff

```text
OBJECT HANDOFF INTERACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO: Robot hands object to human; human receives and acknowledges

    Phase 1: APPROACH          Phase 2: PRESENT           Phase 3: RELEASE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•           â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         â”Œâ”€â”€â”€â”                     â”Œâ”€â”€â”€â”                      â”Œâ”€â”€â”€â”
         â”‚ H â”‚                     â”‚ H â”‚                      â”‚ H â”‚
         â””â”€â”¬â”€â”˜                     â””â”€â”¬â”€â”˜                      â””â”€â”¬â”€â”˜
           â”‚                         â”‚ â† hand extends           â”‚â—â”€ object
           â”‚                         â”‚                          â”‚
           â”‚         â—               â”‚    â—                     â”‚
           â”‚        â•±â”‚â•²              â”‚   â•±â”‚â•²                    â”‚
           â”‚         â”‚               â”‚    â”‚                     â”‚
       â”Œâ”€â”€â”€â”´â”€â”€â”€â”     â”‚           â”Œâ”€â”€â”€â”´â”€â”€â”€â”                 â”Œâ”€â”€â”€â”´â”€â”€â”€â”
       â”‚       â”‚    â—â”¤           â”‚       â”œâ—                â”‚       â”‚
       â”‚ Robot â”‚    â–ˆâ”‚           â”‚ Robot â”‚â–ˆâ”€ gripper open  â”‚ Robot â”‚
       â”‚       â”‚     â”‚           â”‚       â”‚                 â”‚       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”˜

    Robot approaches     Robot extends arm,         Human grasps object,
    optimal handoff      offers object at           robot detects grip force,
    distance (0.5-0.8m)  comfortable height         releases gripper


UNITY SIMULATION REQUIREMENTS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Human NPC with inverse kinematics (reach animation)
â€¢ Gripper force/contact sensing
â€¢ Handoff position calculation (human arm reach zone)
â€¢ Release trigger based on detected grasp


STATE MACHINE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    human detected    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    in range    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IDLE    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ APPROACH  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  PRESENT  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    timer expired     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    grasp detected    â”‚
â”‚  IDLE    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  RETRACT  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ROS 2 TOPICS FOR HANDOFF:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/human_pose         â†’ geometry_msgs/PoseStamped (hand tracking)
/handoff_command    â†’ std_msgs/String (initiate, abort)
/gripper_force      â†’ std_msgs/Float64 (grasp detection)
/handoff_state      â†’ std_msgs/String (approaching, presenting, complete)
```

## Pattern 2: Social Navigation

```text
SOCIAL NAVIGATION PATTERNS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO: Robot navigates through space while respecting human comfort zones

PROXEMICS ZONES (Hall's Model):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                PUBLIC                    â”‚
                    â”‚              (3.6m - 7.6m)               â”‚
                    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                    â”‚    â”‚         SOCIAL              â”‚      â”‚
                    â”‚    â”‚       (1.2m - 3.6m)         â”‚      â”‚
                    â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
                    â”‚    â”‚   â”‚     PERSONAL        â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚   (0.45m - 1.2m)    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”‚  INTIMATE   â”‚    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”‚ (< 0.45m)   â”‚    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”‚    â”Œâ”€â”€â”€â”    â”‚    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”‚    â”‚ H â”‚    â”‚    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â”‚    â””â”€â”€â”€â”˜    â”‚    â”‚   â”‚      â”‚
                    â”‚    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚      â”‚
                    â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
                    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


NAVIGATION BEHAVIORS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. PASSING (Hallway)                    2. YIELDING (Doorway)

   H â†’ â†’                                      â”Œâ”€â”€â”€â”€â”
                                              â”‚    â”‚
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       H â†’ â”‚    â”‚
                     â† Robot avoids           â”‚    â”‚
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       R â—‹ â”‚    â”‚ Robot waits
                                              â”‚    â”‚
   Robot detects human, moves right           â””â”€â”€â”€â”€â”˜


3. FOLLOWING (Guidance)                 4. GROUP NAVIGATION

         H                                  H   H
         â”‚                                   \ /
         â”‚ 1.5m                               â—  Group center
         â”‚                                   / \
         R                                  H   R â†’ maintains
                                                   formation
   Robot maintains following
   distance, matches pace


UNITY SIMULATION ELEMENTS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Multiple human NPCs with NavMesh navigation
â€¢ Randomized walking patterns and speeds
â€¢ Group formation behaviors
â€¢ Dynamic obstacle spawning
â€¢ Crowd density variation


ROS 2 TOPICS FOR SOCIAL NAV:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/people_tracker     â†’ people_msgs/People (detected humans)
/social_costmap     â†’ nav_msgs/OccupancyGrid (augmented with social costs)
/human_prediction   â†’ nav_msgs/Path (predicted human trajectories)
/robot_intention    â†’ geometry_msgs/PoseArray (robot's planned path)
```

## Pattern 3: Gesture Recognition

```text
GESTURE RECOGNITION INTERACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO: Robot recognizes and responds to human gestures

COMMON GESTURE VOCABULARY:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    STOP        â”‚    COME HERE   â”‚    POINT       â”‚    WAVE        â”‚
â”‚                â”‚                â”‚                â”‚                â”‚
â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚
â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚
â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚
â”‚   â•â•â•â•ªâ•â•â•     â”‚      â•²â”‚        â”‚      â•±â”‚â”€â”€â”€â”€â–º   â”‚      â•±â”‚~~~     â”‚
â”‚      â”‚        â”‚       â”‚â•²       â”‚      â”‚        â”‚      â”‚        â”‚
â”‚     â•± â•²       â”‚      â•± â•²       â”‚     â•± â•²       â”‚     â•± â•²       â”‚
â”‚                â”‚                â”‚                â”‚                â”‚
â”‚   Palm out     â”‚   Beckoning    â”‚   Index finger â”‚   Side-to-side â”‚
â”‚   Robot stops  â”‚   Robot approachâ”‚  Robot looks  â”‚   Greeting     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    THUMBS UP   â”‚    THUMBS DOWN â”‚    GRAB/TAKE   â”‚    PUSH AWAY   â”‚
â”‚                â”‚                â”‚                â”‚                â”‚
â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚     â”Œâ”€â”€â”€â”      â”‚
â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚     â”‚ H â”‚      â”‚
â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚    â”€â”´â”€â”¬â”€â”´â”€     â”‚
â”‚      â”‚ğŸ‘       â”‚      â”‚ğŸ‘       â”‚     âœŠâ”‚        â”‚   â•â•â•â•ªâ•â•â•â–º    â”‚
â”‚      â”‚        â”‚      â”‚        â”‚      â”‚        â”‚      â”‚        â”‚
â”‚     â•± â•²       â”‚     â•± â•²       â”‚     â•± â•²       â”‚     â•± â•²       â”‚
â”‚                â”‚                â”‚                â”‚                â”‚
â”‚   Confirmation â”‚   Rejection    â”‚   Request obj  â”‚   Back away    â”‚
â”‚   Continue taskâ”‚   Stop/redo    â”‚   Robot offers â”‚   Robot retreatsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


GESTURE RECOGNITION PIPELINE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Unity Cameraâ”‚â”€â”€â”€â–ºâ”‚ Image to    â”‚â”€â”€â”€â–ºâ”‚ Pose        â”‚â”€â”€â”€â–ºâ”‚ Gesture     â”‚
â”‚ (RGB stream)â”‚    â”‚ ROS 2       â”‚    â”‚ Estimation  â”‚    â”‚ Classifier  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚ Robot       â”‚â—„â”€â”€â”€â”‚ Behavior    â”‚â—„â”€â”€â”€â”‚ Gesture     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Action      â”‚    â”‚ Selector    â”‚    â”‚ Message     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


UNITY SIMULATION FEATURES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Human avatars with gesture animations (Mixamo/custom)
â€¢ Random gesture triggering for training data
â€¢ Varied lighting conditions
â€¢ Multiple camera viewpoints
â€¢ Occlusion scenarios (partial visibility)


ROS 2 TOPICS FOR GESTURES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/camera/image_raw   â†’ sensor_msgs/Image (RGB from Unity)
/body_pose          â†’ geometry_msgs/PoseArray (skeleton keypoints)
/gesture_detected   â†’ std_msgs/String (recognized gesture label)
/gesture_confidence â†’ std_msgs/Float64 (recognition confidence)
```

## Pattern 4: Collaborative Task

```text
COLLABORATIVE MANIPULATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SCENARIO: Human and robot work together to move a large object

COOPERATIVE LIFTING:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Initial                Lifting                 Moving
    â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€

    â”Œâ”€â”€â”€â”                 â”Œâ”€â”€â”€â”                   â”Œâ”€â”€â”€â”
    â”‚ H â”‚                 â”‚ H â”‚                   â”‚ H â”‚â”€â”€â”€â–º
    â””â”€â”¬â”€â”˜                 â””â”€â”¬â”€â”˜                   â””â”€â”¬â”€â”˜
      â”‚                     â”‚                       â”‚
    â”Œâ”€â”´â”€â”                 â”Œâ”€â”´â”€â”                   â”Œâ”€â”´â”€â”
    â”‚â–ˆâ–ˆâ–ˆâ”‚                 â”‚â–ˆâ–ˆâ–ˆâ”‚                   â”‚â–ˆâ–ˆâ–ˆâ”‚â”€â”€â”€â–º
    â””â”€â”¬â”€â”˜                 â””â”€â”¬â”€â”˜                   â””â”€â”¬â”€â”˜
      â”‚                     â”‚                       â”‚
   â”Œâ”€â”€â”´â”€â”€â”              â”Œâ”€â”€â”´â”€â”€â”                 â”Œâ”€â”€â”´â”€â”€â”
   â”‚Robotâ”‚              â”‚Robotâ”‚                 â”‚Robotâ”‚â”€â”€â”€â–º
   â””â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”˜

  Both grasp      Synchronized lift      Coordinated movement
  opposite ends   based on force feedback  human leads, robot follows


FORCE COORDINATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Human applies force â†’      Robot senses and responds

         Fh = 10N â†’            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”Œâ”€â”€â”€â”                      â”‚ Impedance Control â”‚
    â”‚ H â”œâ”€â”€â”€â”€â”€â”€â”               â”‚                   â”‚
    â””â”€â”€â”€â”˜      â”‚               â”‚ Fr = -Kp(x-xd)    â”‚
               â”‚               â”‚    - Kd(v-vd)     â”‚
         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”         â”‚                   â”‚
         â”‚   OBJECT  â”‚         â”‚ Allows compliant  â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚ motion following  â”‚
               â”‚               â”‚ human intention   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        Robot        â”‚
    â”‚    (force sensing)  â”‚    Fr = 8N (compliant follow)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ROS 2 TOPICS FOR COLLABORATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/wrench_human_estimate  â†’ geometry_msgs/Wrench (estimated human force)
/robot_wrench           â†’ geometry_msgs/Wrench (robot applied force)
/object_pose            â†’ geometry_msgs/Pose (shared object pose)
/collaboration_state    â†’ std_msgs/String (waiting, grasped, lifting, moving)
```

## Unity Implementation Checklist

```text
UNITY HRI SCENE REQUIREMENTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â–¡ HUMAN AVATARS
  â”œâ”€â”€ Rigged humanoid mesh (Mixamo or custom)
  â”œâ”€â”€ Animator controller with HRI states
  â”œâ”€â”€ IK setup for hand reaching
  â””â”€â”€ NavMeshAgent for navigation

â–¡ ROBOT MODEL
  â”œâ”€â”€ URDF imported via Unity Robotics Hub
  â”œâ”€â”€ ArticulationBody components for physics
  â”œâ”€â”€ Gripper with contact sensing
  â””â”€â”€ Sensor simulations (cameras, force)

â–¡ ENVIRONMENT
  â”œâ”€â”€ Indoor scene (home, office, hospital)
  â”œâ”€â”€ Obstacles and furniture
  â”œâ”€â”€ Lighting variations (time of day)
  â””â”€â”€ NavMesh baked for navigation

â–¡ INTERACTION TRIGGERS
  â”œâ”€â”€ Proximity detection (OnTriggerEnter)
  â”œâ”€â”€ Gesture animation triggers
  â”œâ”€â”€ Object spawn points
  â””â”€â”€ Task initiation zones

â–¡ ROS 2 INTEGRATION
  â”œâ”€â”€ ROSConnection singleton configured
  â”œâ”€â”€ Publishers for sensor data
  â”œâ”€â”€ Subscribers for commands
  â””â”€â”€ Service for reset/spawn
```

## Usage in Book

- **Referenced in**: Chapter 5 (Core Concept 4: Human-Robot Interaction Scenarios)
- **Purpose**: Illustrate HRI scenarios that benefit from Unity's visual and physics capabilities
- **Learning Goal**: Design HRI simulations for training socially-aware robot behaviors

## Key Takeaways

1. **Object handoff**: Requires force sensing, human hand tracking, and coordinated timing
2. **Social navigation**: Must respect proxemics zones; Unity enables realistic crowd simulation
3. **Gesture recognition**: Unity provides photorealistic training data with diverse humans/conditions
4. **Collaborative tasks**: Force/impedance control essential; Unity simulates contact physics
5. **Human NPCs**: Use Mixamo animations + NavMesh for realistic movement patterns
6. **Training diversity**: Unity enables randomization of humans, lighting, scenarios for robust ML
